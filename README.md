

# Fruchtklassifikations-Projekt
## ProjektÃ¼bersicht
Dieses Projekt zielt darauf ab, ein Modell zu entwickeln, das verschiedene Fruchttypen (z. B. Ã„pfel, Bananen, Trauben) basierend auf ihren Eigenschaften wie Gewicht und GrÃ¶ÃŸe klassifiziert. Dabei werden zwei AnsÃ¤tze evaluiert:

1. Logistische Regression
2. Entscheidungsbaum

Die Analyse umfasst die Datenaufbereitung, explorative Datenanalyse, Modelltraining und Hyperparameter-Tuning. Die Modelle werden anhand verschiedener Metriken wie Genauigkeit, F1-Score und ROC-AUC verglichen.

# Projektstruktur
Das Projekt ist in mehrere Ordner unterteilt, um die Organisation und Nachvollziehbarkeit zu gewÃ¤hrleisten:

ðŸ“‚ data

      â”œâ”€â”€ fruit_data.xlsx              #Rohdatensatz
      â”œâ”€â”€ fruit_data_cleaned.xlsx      #Bereinigte und aufbereitete Daten
ðŸ“‚ models
      
      â”œâ”€â”€ model_training.ipynb         # Notebook mit Modelltraining und Evaluierung

ðŸ“‚ notebooks

      â”œâ”€â”€ data_preparation.ipynb       # Datenaufbereitung und Bereinigung
      â”œâ”€â”€ exploratory_analysis.ipynb   # Explorative Datenanalyse
   
ðŸ“„ README.md               

# Datenbeschreibung
Die Daten enthalten die folgenden Variablen:

**fruit_type**: Zielvariable (Fruchttyp: Apple, Banana, Grape).

**weight**: Gewicht der Frucht (numerisch).

**size**: GrÃ¶ÃŸe der Frucht (kategorisch: Tiny, Small, Medium, Large).

**color**: Farbe der Frucht (kategorisch: Yellow, Red, Purple, Pink, Green, Creamy White, Black).

Die Daten wurden bereinigt und nach fehlenden Werten geprÃ¼ft. Details dazu finden Sie im Notebook data_preparation.ipynb.

# DurchgefÃ¼hrte Schritte
1. Datenvorbereitung
      - Entfernen von fehlenden oder fehlerhaften Werten.
      - Transformation kategorischer Variablen in numerische Werte.
      - Optional: Skalierung numerischer Variablen.
2. Explorative Datenanalyse
      - Untersuchung der Verteilung der Daten.
      - Visualisierungen wie Boxplots, Korrelationsmatrizen und Histogramme.
      - Beispiel: Gewichtsunterschiede zwischen Fruchttypen.
3. Modelltraining
      - Training eines Entscheidungsbaums und einer logistischen Regression.
      - Anwendung von Hyperparameter-Tuning (Grid Search) zur Optimierung der Modelle.
      - Vergleich der Modellleistungen anhand:
            - Genauigkeit
            - F1-Score
            - ROC-AUC
5. Ergebnisse
Die logistische Regression zeigte eine Genauigkeit von 93% und schnitt insgesamt besser ab.

Der Entscheidungsbaum erreichte eine Ã¤hnliche Genauigkeit, jedoch mit geringfÃ¼gig niedrigeren AUC-Werten.

